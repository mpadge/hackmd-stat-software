<!-- Edit the .Rmd not the .md file -->

## Machine Learning Software


R has an extensive and diverse ecosystem of Machine Learning (ML) software
which is very well described in the corresponding [CRAN Task
View](https://cran.r-project.org/web/views/MachineLearning.html). Unlike most
other categories of statistical software considered here, the primary
distinguishing feature of ML software is not algorithmic, rather pertains to a
*workflow* typical of machine learning tasks. In particular, we consider ML
software to be software which approaches data analysis via the two primary
steps of:

1.  Passing a set of *training* data to an algorithm in order to generate a
    candidate mapping between that data and some form of pre-specified output
    or response variable. Such mappings will be referred to here as “models”,
    with a single analysis of a single set of training data generating one
    model.
2.  Passing a set of test data to the model(s) generated by the first step in
    order to derive some measure of predictive accuracy for that model.

A single ML task generally yields two distinct outputs:

1. The model derived in the first of the previous steps; and
2. Associated statistics of model performance (as evaluated within the context
   of the test data used to assess that performance).

**A Machine Learning Workflow**

Given those initial considerations, we now attempt the difficult task of
envisioning a typical standard workflow for inherently diverse ML software. The
following workflow ought to be considered an "extensive" workflow, with shorter
versions, and correspondingly more restricted sets of standards, possible
dependent upon envisioned areas of application. For example, the workflow
presumes input data to be too large to be stored as a single entity in local
memory. Adaptation to situations in which all training data can be loaded into
memory may mean that some of the following workflow stages, and therefore
corresponding standards, may not apply. 

Just as typical workflows are potentially very diverse, so are outputs of ML
software, which depend on areas of application and intended purpose of
software. The following refers to the "desired output" of ML software,
a phrase which is intentionally left non-specific, but which it intended to
connote any and all forms of "response variable" and other "pre-specified
outputs" such as categorical labels or validation data, along with outputs
which may not necessarily be able to be pre-specified in simple uni- or
multi-variate form, such as measures of distance between sets of training and
validation data. 

Such "desired outputs" are presumed to be quantified in terms of a "loss" or
"cost" function (hereafter, simply "loss function") quantifying some measure of
distance between a model estimate (resulting from applying the model to one or
more components of a training data set) and a pre-defined "valid" output
(during training), or a test data set (following training).

Given the foregoing considerations, we consider a typical ML workflow to
progress through (at least some of) the following steps:

1. Obtain a local copy of input data, often as multiple *objects* (either
   on-disk or in memory) in some suitably structured form such as in a series
   of sub-directories or accompanied by additional data defining the structural
   properties of input objects. Regardless of form, multiple objects are
   commonly given generic labels which distinguish between `training` and
   `test` data, along with optional additional categories and labels such as
   `validation` data used, for example, to determine accuracy of models applied
   to training data yet prior to testing.
2. Define transformations of input data, including but not restricted to,
   broadcasting dimensions (as defined below) and standardising data ranges
   (typically to defined values of mean and standard deviation).
3. Define what kind of model will be applied to map the input data on to the
   desired output. ML software often allows the use of pre-trained models, in
   which case this this step includes downloading or otherwise obtaining
   a pre-trained model, along with specification of which aspects of those
   models are to be modified through application to a particular set of
   training and validation data.
4. Define parameters controlling how the algorithm will progress towards an
   optimal solution, commonly including but not limited to:
    a. The type of algorithm used to explore the search space (for example some
       kind of gradient descent algorithm).
    b. The kind of loss function will be used to quantify distance between
       model estimates and desired output.
5. Apply the specified model to the training data to generate a series of
   estimates from the specified loss function. This stage may also include
   specifying parameters such as stopping or exit criteria, and parameters
   controlling batch processing of input data. Moreover, this stage may involve
   retaining some of the following additional data:
    a. Potential "pre-processing" stages such as initial estimates of optimal
       learning rates (see above).
    b. Details of summaries of actual paths taken through the search space
       towards convergence on local or global minimum.
6. Measure the performance of the trained model when applied to the test data
   set, generally requiring the specification of a metric of model performance
   or accuracy.

Importantly, ML workflows may be partly iterative. This may in turn potentially
confound distinctions between training and test data, and accordingly confound
expectations commonly placed upon statistical analyses of statistical
independence of response variables (such as, for example, with linear
regression). ML routines such as cross-validation repeatedly partition data
between training and test sets. Resultant models can then not be considered to
have been developed through application to any single set of truly
"independent" data. In the context of the standards that follow, these
considerations admit a potential lack of absolute clarity in any notional
categorical distinction between training and test data.

The preceding workflow mentioned a couple of concepts the definitions of which
may be seen by clicking on the corresponding items below. Following that, we
proceed to the definition of standards for ML software, enumerated and
developed with reference to the steps of the workflow. As described above,
these steps may not be applicable to all ML software, and so all of the
following standards should be considered to be conditioned on "where
applicable." In order that the following standards initially adhere to the
enumeration of workflow steps given above, more general standards pertaining to
aspects such as documentation and testing are given following the initial six
"workflow" standards.




<details>
<summary>
Click for a definition of *broadcasting*, referred to in Step 2, above.
</summary>
<p>

The following definition comes from a vignette for the [`rray`
package](https://github.com/r-lib/rray) named
[*Broadcasting*](https://rray.r-lib.org/articles/broadcasting.html).

- ***Broadcasting*** is, "repeating the dimensions of one object to match the
  dimensions of another.”

This concept runs counter to aspects of standards in other categories, which
often suggest that functions should error when passed input objects which do
not have commensurate dimensions. Broadcasting is a pre-processing step which
enables objects with incommensurate dimensions to be dimensionally reconciled.

The following demonstration is taken directly from the [`rray`
package](https://github.com/r-lib/rray) (which is not currently on CRAN).

```{r rray}
library (rray)
a <- array(c(1, 2), dim = c(2, 1))
b <- array(c(3, 4), dim = c(1, 2))
# rbind (a, b) # error!
rray_bind (a, b, .axis = 1)
rray_bind (a, b, .axis = 2)
```

Broadcasting is commonly employed in ML software because it enables ML
operations to be implemented on objects with incommensurate dimensions.
One example is image analysis, in which training data may all be dimensionally
commensurate, yet test images may have different dimensions. Broadcasting
allows data to be submitted to ML routines regardless of potentially
incommensurate dimensions.

</p>
</details>

<details>
<summary>
Click for a definition of *learning rate*, referred to in Step 5, above.
</summary>
<p>

-   ***Learning Rate*** (generally) determines the step size used to search for
    local optima as a fraction of the local gradient.

This parameter is particularly important for training ML algorithms like
neural networks, the results of which can be very sensitive to
variations in learning rates. A useful overview of the importance of
learning rates, and a useful approach to automatically determining
appropriate values, is given in [this blog
post](https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html).

</p>
</details>


### Input Data Structures and Validation

Many of the following standards refer to the labelling of input data as
"testing" or "training" data, along with potentially additional labels such as
"validation" data. In regard to such labelling, the following two standards apply,

- **ML1.0** Documentation should make a clear conceptual distinction between
  training and test data (even where such may ultimately be confounded as
  described above.)
    - **ML1.0a** Where these terms are ultimately eschewed, these should
      nevertheless be used in initial documentation, along with clear
      explanation of, and justification for, alternative terminology.
- **ML1.1** Absent clear justification for alternative design decisions, input
  data should be expected to be labelled "test", "training", and, where
  applicable, "validation" data.
    - **ML1.1a** The presence and use of these labels should be explicitly
      confirmed via pre-processing steps (and tested in accordance with
      **ML7.0**, below).
    - **ML1.1b** Matches to expected labels should be case-insensitive and
      based on partial matching such that, for example, "Test", "test", or
      "testing" would all suffice.

The following three standards (**ML1.2**--**ML1.4**) represent three possible
design intentions for ML software. Only one of these three will generally be
applicable to any one piece of software, although it is nevertheless possible
that more than one of these standards may apply. The first of these three
standards applies to ML software which is intended to process, or capable of
processing, input data as a single (generally tabular) object.

- **ML1.2** Training and test data sets for ML software should be able to be
  input as a single, generally tabular, data object, with the two kinds of data
  distinguished either by
    - A specified variable containing, for example, `TRUE`/`FALSE` or `0`/`1`
      values, or which uses some other system such as missing (`NA`) values to
      denote test data); and/or
    - An additional parameter designating case or row numbers, or labels of
      test data.

The second of these three standards applies to ML software which is intended to
process, or capable of processing, input data represented as multiple objects
which exist in local memory.

- **ML1.3** Input data should be clearly partitioned between training and test
  data (for example, through having each passed as a distinct `list` item), or
  should enable an additional means of categorically distinguishing training
  from test data (such as via an additional parameter which provides explicit
  labels). Where applicable, distinction of validation and any other data
  should also accord with this standard.

The third of these three standards for data input applies to ML software for
which data are expected to be input as references to multiple external objects,
generally expected to be read from either local or remote connections.

- **ML1.4** Training and test data sets, along with other necessary components
  such as validation data sets, should be stored in their own distinctly
  labelled sub-directories (for distinct files), or according to an explicit
  and distinct labelling scheme (for example, for database connections).
  Labelling should in all cases adhere to **ML1.1**, above.

The following standard applies to all ML software regardless of the
applicability or otherwise of the preceding three standards. 

- **ML1.5** ML software should implement a single function which summarises the
  contents of test and training (and other) data sets, minimally including
  counts of numbers of cases, records, or files, and potentially extending to
  tables or summaries of file or data types, sizes, and other information.

#### Missing Values

Missing data are handled differently by different ML routines, and it is also
difficult to suggest generally applicable standards for pre-processing missing
values in ML software. The following standards attempt to cover a practical
range of typical approaches and applications.

- **ML1.6** ML software which does not admit missing values, and which expects
  no missing values, should implement explicit pre-processing routines to
  identify whether data has any missing values, and should generally error
  appropriately and informatively when passed data with missing values. In
  addition, ML software which does not admit missing values should:
    - **ML1.6a** Explain why missing values are not admitted.
    - **ML1.6b** Provide explicit examples (in function documentation,
      vignettes, or both) for how missing values may be imputed, rather than
      simply discarded.
- **ML1.7** ML software which admits missing values should clearly document how
  such values are processed.
    - **ML1.7a** Where missing values are imputed, software should offer
      multiple user-defined ways to impute missing data.
    - **ML1.7b** Where missing values are imputed, the precise imputation steps
      should also be explicitly documented, either in tests (see **ML7.2**
      below), function documentation, or vignettes.
- **ML1.8** ML software should enable equal treatment of missing values for
  both training and test data, with optional user ability to control
  application to either one or both.

### Transformation and Pre-processing of Input Data

Standards for most other categories of statistical software suggest that
pre-processing routines should ensure that input data sets are commensurate,
for example, through having equal numbers of cases or rows. In contrast, ML
software is commonly intended to accept input data which can not be guaranteed
to be dimensionally commensurate, such as software intended to process
rectangular image files which may be of different sizes.

- **ML2.0** ML software which uses broadcasting to reconcile dimensionally
  incommensurate input data should offer an ability to at least optionally
  record transformations applied to each input file.

Beyond broadcasting and dimensional transformations, the following standards
apply to the pre-processing stages of ML software. 

- **ML2.1** A dedicated function should enable pre-processing steps to be
  defined and parametrized.
    - **ML2.1a** That function should return an object which can be directly
      submitted to a specified model (see section 3, below).
    - **ML2.1b** Absent explicit justification otherwise, that return object
      should have a defined class minimally intended to implement a default
      `print` method which summarizes the input data set (as per **ML1.2**
      above) and associated transformations (see the following standard).
- **ML2.2** ML software which requires or relies upon numeric transformations
  of input data (such as change in mean values or variances) should allow
  explicit specification of target values, rather than rely on default generic
  values (such as transformations to z-scores).
    - **ML2.2a** Those values should be recorded in the object returned by the
      function described in the preceding standard (**ML2.18**).
    - **ML2.2b** Where the parameters have default values, reasons for those
      particular defaults should be explicitly described.
    - **ML2.2c** Any extended documentation (such as vignettes) which
      demonstrates the use of explicit values for numeric transformations
      should explicitly describe why particular values are used.

### Model Specification

A "model" in the context of ML software is understood to be a means of
specifying a mapping between input and output data, generally applied to
training and validation data. Model specification is the step of specifying
*how* such a mapping is to be constructed. The specification of *what* the
values of such a model actually are occurs through training the model, and is
described in the following sub-section.

- **ML3.0** Model specification should be implemented as a distinct stage prior
  to actual model fitting or training. In particular,
    - **ML3.0a** A dedicated function should enable models to be specified
      without actually fitting or training them.
    - **ML3.0b** That function should return an object which can be directly
      trained as described in the following sub-section.
    - **ML3.0** That return object should have a defined class minimally
      intended to implement a default `print` method which summarises the model
      specification, including values of all relevant parameters.
- **ML3.1** ML software should allow the use of both untrained models,
  specified through model parameters only, as well as pre-trained models.
- **ML3.2** ML software should enable different models to be applied to the
  object specifying data inputs and transformations (see sub-sections 1--2,
  above) without needing to re-define those preceding steps.
- **ML3.3** Where ML software implements its own distinct classes of model
  objects (in the sense intended here), the properties and behaviours of those
  specific classes of objects should be explicitly compared with objects
  produced by other ML software. In particular, where possible,
    - **ML3.3** ML software should provide extended documentation (as vignettes
      or equivalent) comparing model objects with those from other ML software,
      noting both unique abilities and restrictions of any implemented classes.
- **ML3.4** Where training rates are used, ML software should provide explicit
  documentation both in all functions which use training rates, and in extended
  form such as vignettes, of the importance of, and/or sensitivity to, different
  values of training rates. In particular,
    - **ML3.4a** Unless explicitly justified otherwise, ML software should
      offer abilities to automatically determine appropriate or optimal
      training rates, either as distinct pre-processing stages, or as implicit
      stages of model training.
    - **ML3.4b** ML software which provide default values for training rates
      should clearly document anticipated restrictions of validity of those
      default values; for example through clear suggestions that
      user-determined and -specified values may generally be necessary or
      preferable.

### Algorithms

- **ML4.0** Parameters controlling optimization algorithms should minimally include:
    - **ML4.0a** Specification of the type of algorithm used to explore the search space.
    - **ML4.0b** The kind of loss function used to assess distance between
      model estimates and desired output.
- **ML4.1** Unless explicitly justified otherwise (for example because ML
  software under consideration is an implementation of one specific algorithm),
  ML software should:
    - **ML4.1a** Implement or otherwise permit usage of multiple ways of exploring search space
    - **ML4.1b** Implement or otherwise permit usage of multiple loss functions.

The specification of optimization algorithms may be implemented as a part of
model specification (in the prior section), or as a distinct step in its own
right. Either way, the following standard applies:

- **ML4.2** ML software should permit specification of optimization algorithms
  in the sense covered by the preceding two standards prior to, and definitely
  not as part of, specification of model training as considered in the
  subsequent sub-section.

That is, the object passed to a model training exercise should contain full
specification of the optimization algorithm.

#### CPU and GPU processing

ML software often involves manipulation of large numbers of rectangular arrays
for which graphics processing units (GPUs) are often more efficient than
central processing units (CPUs). ML software thus commonly offers options to
train models using either CPUs or GPUs. While these standards do not currently
suggest any particular design choice in this regard, we do note the following:

- **ML4.3** For ML software in which algorithms are coded in C++,
  user-controlled use of either CPUs or GPUs (on NVIDIA processors at least)
  should be implemented through direct use of
  [`libcudacxx`](https://github.com/NVIDIA/libcudacxx).

This library can be "switched on" through activating a single C++ header file
to switch from CPU to GPU.

### Model Training

- **ML5.0** ML software should generally implement a unified single-function
  interface to model training, able to receive as input a model specified
  according to all preceding standards. In particular, models with
  categorically different specifications, such as different model architectures
  or optimization algorithms, should be able to be submitted to the same model
  training function.
- **ML5.1** ML software should retain explicit information on paths taken as an
  optimizer advances towards minimal loss. Such information should minimally
  include:
    - **ML5.1a** Specification of all model-internal parameters, or equivalent
      hashed representation.
    - **ML5.1b** The value of the loss function at each point
    - **ML5.1c** Information used to advance to next point, for example
      quantification of local gradient.
- **ML5.2** The subsequent extraction of information retained according to the
  preceding standard should be explicitly documented.

#### Batch Processing

The following standards apply to ML software which implements batch processing,
commonly to train models on data sets too large to be loaded in their entirety
into memory.

- **ML5.3** All parameters controlling batch processing and associated
  terminology should be explicitly documented, and it should not, for example,
  be presumed that users will understand the definition of "epoch" as
  implemented in any particular ML software.

According to that standard, it would for example be inappropriate to have
a parameter, `nepochs`, described as `"Number of epochs used in model
training"`. Rather, the definition and particular implementation of "epoch"
must be explicitly defined.

- **ML5.4** Explicit guidance should be provided on selection of appropriate
  values for parameter controlling batch processing, for example, on trade-offs
  between batch sizes and numbers of epochs (with both terms explicitly defined
  in accordance with the preceding standard).
- **ML5.5** ML software may optionally include a function to estimate likely
  time to train a specified model, through estimating initial timings from
  a small sample of the full batch.
- **ML5.6** ML software should by default provide explicit information on the
  progress of batch jobs (even where those jobs may be implemented in parallel
  on GPUs). That information may be optionally suppressed through additional
  parameters.

#### Re-sampling

ML software does not always rely on pre-specified and categorical distinctions
between training and test data. For example, models may be fit to what is
effectively one single data set in which specified cases or rows are used as
training data, and the remainder as test data. Re-sampling generally refers to
the practice of re-defining categorical distinctions between training and test
data. One training run accordingly connotes training a model on one particular
set of training data and then applying that model to the specified set of test
data. Re-sampling starts that process anew, through constructing an alternative
categorical partition between test and training data.

Even where test and training data are distinguished by more than a simple
data-internal category (such as a labelling column), for example,
by being stored in distinctly-named sub-directories, re-sampling may be
implemented by effectively shuffling data between training and test
sub-directories.

- **ML5.7.X** ML software should provide an ability to combine results from
  multiple re-sampling iterations using a single parameter specifying numbers
  of iterations.
- **ML5.8** Absent any additional specification, re-sampling algorithms should
  by default partition data according to proportions of original test and
  training data.
    - **ML5.8a** Re-sampling routines of ML software should nevertheless offer
      an ability to explicitly control or override such default proportions of
      test and training data.

### Model Output and Performance

- **ML6.0** For ML software able to perform classification tasks, the return
  object should provide direct access to a classification ("confusion") matrix.
- **ML6.1** For ML software able to perform classification tasks, the return
  object should provide direct access to classification probabilities.

### Documentation


- **ML1.0** Descriptions of ML software should make explicit reference to
  a workflow which separates training and testing stages, and which clearly
  indicates a need for distinct training and test data sets.

The following standard applies to packages which are intended or other able to
only encompass a restricted subset of the six primary workflow steps enumerated
at the outset. Envisioned here are packages explicitly intended to aid one
particular aspect of the general workflow envisioned here, such as
implementations of ML optimization functions, or specific loss measures.

- **MLX.X** ML software intentionally designed to address only a restricted
  subset of the workflow described here should clearly document how it can be
  embedded within a typical *full* ML workflow in the sense considered here.


### Testing

- **ML7.0** Test should explicitly confirm partial and case-insensitive
  matching of "test", "train", and, where applicable, "validation" data.
- **ML7.1** Tests should demonstrate effects of different numeric scaling of
  input data (see **ML2.2**).
- **ML7.2** For software which imputes missing data, tests should compare
  internal imputation with explicit code which directly implements imputation
  steps (even where such imputation is a single-step implemented via some
  external package). These tests serve as an explicit reference for how
  imputation is performed.
- **ML7.3** Where model objects are implemented as distinct classes, tests
  should explicitly compare the functionality of these classes with
  functionality of equivalent classes for ML model objects from other packages.
    - **ML7.3a** These tests should explicitly identify restrictions on the
      functionality of model objects in comparison with those of other
      packages.
    - **ML7.3b** These tests should explicity identify functional advantages
      and unique abilities of the model objects in comparison with those of
      other packages.
- **ML7.4** ML software should explicit document the effects of different
  training rates, and in particular should demonstrate divergence from optima
  with inappropriate training rates.
- **ML7.5** ML software which implements routines to determine optimal training
  rates (see **ML3.4**, above) should implement tests to confirm the optimality
  of resultant values.
- **ML7.6** ML software which implement independent training "epochs" should
  demonstrate in tests the effects of lesser versus greater numbers of epochs.
- **ML7.7** ML software should explicitly test different optimization
  algorithms, even where software is intended to implement one specific
  algorithm.
- **ML7.8** ML software should explicitly test different loss functions, even
  where software is intended to implement one specific measure of loss.
- **ML7.9** Tests should explicitly compare all possible combinations in
  categorical differences in model architecture, such as different model
  architectures with same optimization algorithms, same model architectures
  with different optimization algorithms, and differences in both.
    - **ML7.9a** Such combinations will generally be formed from multiple
      categorical factors, for which explicit use of functions such as
      [`expand.grid()`](https://stat.ethz.ch/R-manual/R-devel/library/base/html/expand.grid.html)
      is recommended.

The following example illustrates:

```{r expand.grid}
architechture <- c ("archA", "archB")
optimizers <- c ("optA", "optB", "optC")
cost_fns <- c ("costA", "costB", "costC")
expand.grid (architechture, optimizers, cost_fns)
```

All possible combinations of these categorical parameters could then be tested
by iterating over the rows of that output.

- **ML7.10** The successful extraction of information on paths taken by
  optimizers (see **ML5.1**, above), should be tested, including testing the
  general properties, but not necessarily actual values of, such data.

